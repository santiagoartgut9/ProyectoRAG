## Proyecto RAG â€” LangChain + Pinecone
ImplementaciÃ³n de un sistema RAG (Retrieval-Augmented Generation) que usa embeddings de Hugging Face, Pinecone como vector DB y un modelo HuggingFace para generaciÃ³n. Incluye: indexaciÃ³n, chunking, upsert en Pinecone, recuperaciÃ³n, cadena RAG, un agente simple tipo tool-based y evaluaciÃ³n por scores.

## ğŸ“‚ Estructura del Proyecto

```text
.
â”œâ”€ .env.example
â”œâ”€ README.md
â”œâ”€ requirements.txt
â”œâ”€ rag_app.py
â”œâ”€ rag_config.py
â”œâ”€ rag_pipeline.py
â”œâ”€ retriever_rag.py
â”œâ”€ embeddings.py
â”œâ”€ create_vector_store.py
â”œâ”€ p.txt
â”œâ”€ evaluation.py
â””â”€ .gitignore
```

## ğŸš€ Arquitectura y Componentes del Proyecto

A continuaciÃ³n se describe la arquitectura lÃ³gica del sistema RAG desarrollado.
El flujo completo sigue una secuencia clara: **carga â†’ procesamiento â†’ indexaciÃ³n â†’ recuperaciÃ³n â†’ generaciÃ³n â†’ evaluaciÃ³n**.

---

## ğŸ§© Arquitectura del Sistema (DescripciÃ³n LÃ³gica)

### 1. **Carga de documentos**
Se leen archivos desde `p.txt` o desde `data/docs/*.txt`.

### 2. **Chunking (fragmentaciÃ³n del texto)**
Los documentos se dividen en segmentos pequeÃ±os utilizando  
`RecursiveCharacterTextSplitter`, permitiendo una mejor indexaciÃ³n semÃ¡ntica.

### 3. **Embeddings**
Cada chunk se convierte en un vector de 1024 dimensiones mediante el modelo:  
**`intfloat/multilingual-e5-large`** (Hugging Face).

### 4. **Base de Datos Vectorial (Vector Store)**
Los vectores se almacenan en **Pinecone Serverless**, utilizando:
- `PineconeVectorStore`
- Se realiza *upsert* para insertar o actualizar embeddings.

### 5. **RecuperaciÃ³n (Retrieval)**
Cuando llega una pregunta:

1. La consulta se convierte en embedding.  
2. Pinecone ejecuta una bÃºsqueda semÃ¡ntica utilizando *cosine similarity*.  
3. Devuelve los **K chunks mÃ¡s relevantes**.

### 6. **GeneraciÃ³n (RAG)**
El modelo generativo **`google/flan-t5-base`** utiliza el contexto recuperado para crear una respuesta coherente y precisa.

### 7. **Agente (tool-based, opcional)**
Incluye un agente simple que puede:
- âœ” Reescribir la pregunta  
- âœ” Ejecutar bÃºsquedas  
- âœ” Generar la respuesta final usando herramientas internas  

### 8. **EvaluaciÃ³n**
El mÃ³dulo de evaluaciÃ³n calcula mÃ©tricas como:
- Puntaje de similitud  
- Exactitud del retrieval  

Los resultados pueden exportarse a **`evaluation.csv`**.

---

## ğŸ“ Componentes principales (archivos)

| Archivo | DescripciÃ³n |
|--------|-------------|
| `rag_app.py` | Script principal: carga docs, hace chunking, upserts, inicializa LLM y el REPL para consultas. |
| `embeddings.py` | (Opcional) FunciÃ³n para inicializar el modelo de embeddings. |
| `create_vector_store.py` | (Opcional) GestiÃ³n de creaciÃ³n del vector store. |
| `retriever_rag.py` | Utilidades de retrieval y adaptaciÃ³n a retriever. |
| `evaluation.py` | Corre consultas masivas y genera `evaluation.csv`. |
| `p.txt` | Base de conocimiento usada para indexar. |
| `requirements.txt` | Dependencias del proyecto. |

---

## ğŸ”§ Requisitos y entorno

- Python **3.10+** (recomendado **3.11**)  
- Espacio libre (los modelos de HuggingFace pueden ocupar varios GB en cachÃ©)  
- ConexiÃ³n a Internet (descarga de modelos y acceso a Pinecone)  
- (Opcional) GPU para acelerar la inferencia  

---

## ğŸ” Variables de entorno necesarias

```env
PINECONE_API_KEY=pcsk_xxx     
PINECONE_HOST=https://proyecto-xxxx.svc.aped-4627-b74a.pinecone.io
PINECONE_INDEX=proyecto
HUGGINGFACEHUB_API_TOKEN=hf_xxx

